{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecece8b0-ad90-4806-83c2-f5431029b128",
   "metadata": {},
   "source": [
    "## üìò HDB Resale Flat Prices\n",
    "\n",
    "### üìå Notebook Description\n",
    "\n",
    "- **Team:** Team A  \n",
    "- **Members:** Ben, Shazlin, Alan  \n",
    "- **Project Name:** HDB Resale Flat Data Engineering Pipeline\n",
    "- **Description:** Implements automated data ingestion from data.gov.sg and performs dataset merging to produce a unified, analysis-ready dataset.\n",
    "- **Data Artifacts:**  \n",
    "    - `/DataLake/<raw files>`  \n",
    "    - `/Staging/Main.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d60d03-32c5-4bef-9054-2ad58bdab094",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdf46943-8398-4c2e-9fa9-ea0abde47c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sqlalchemy psycopg2-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a646714a-e9f8-480b-980f-35a2965c9051",
   "metadata": {},
   "source": [
    "### üì¶ Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39b2e99-0440-42b7-a7f9-e6ff71893c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "/* JupyterLab output font size (print, text output) */\n",
       ".jp-OutputArea-output pre {\n",
       "    font-size: 12px !important;\n",
       "}\n",
       "\n",
       "/* Pandas DataFrame font size */\n",
       "table.dataframe td, table.dataframe th {\n",
       "    font-size: 10px !important;\n",
       "}\n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "import pandas as pd\n",
    "from PSQL import PSQL\n",
    "\n",
    "#---Customized-----------------------------------------\n",
    "import control_output\n",
    "pd.set_option(\"display.float_format\", \"{:,.2f}\".format)\n",
    "control_output.css"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bbbdca-192d-4c60-ab36-a4b710b3df12",
   "metadata": {},
   "source": [
    "### üß© Initialize Class Instance: PSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78a5a51b-5842-4df6-a636-ee11c8a8ea09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully!\n"
     ]
    }
   ],
   "source": [
    "psql=PSQL()\n",
    "\n",
    "#sql=text(\"CREATE DATABASE hdb;\")\n",
    "#psql.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a152042-a450-4d82-9c52-8c13ea36a719",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Define Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f14f779-e78a-4896-8cdd-5865b9b85065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_table(data_file, info):\n",
    "\n",
    "    index_name = info['index_name']\n",
    "    table_name = info['table_name']\n",
    "\n",
    "    if \"/\" not in data_file:\n",
    "        data_file = f\"../Project-HDB-Store/staging/{data_file}\"\n",
    "\n",
    "    df = pd.read_csv(data_file,\n",
    "                     low_memory=False,\n",
    "                     parse_dates=[index_name],   # convert to datetime during read\n",
    "                     index_col=index_name)\n",
    "\n",
    "    # Create engine\n",
    "    engine = create_engine(psql.connection_url)\n",
    "    \n",
    "    # Insert into table\n",
    "    df.to_sql(table_name, engine, if_exists=\"replace\", index=True, index_label=index_name)\n",
    "\n",
    "    #sql = f\"CREATE INDEX idx_{table_name}_{index_name} ON {table_name} ({index_name})\";\n",
    "    #sql = text(sql)\n",
    "    #psql.execute(sql)\n",
    "    #print(sql)\n",
    "\n",
    "    sql = text(f\"SELECT count(*) FROM {table_name}\")\n",
    "    result = psql.query(sql)\n",
    "    counts = result.iloc[0].values[0]\n",
    "\n",
    "    print(f\"CSV: {data_file:24} imported successfully. Number of records : {counts:>6}, {table_name}:{index_name}\")\n",
    "    print(\"-\" * 125)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5d800-afce-49b4-8492-226f9293ff35",
   "metadata": {},
   "source": [
    "### ‚ñ∂Ô∏è Execute File Processor 1: **Populate Tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d536df6e-eec0-4f73-8770-5da6160177dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 1\n",
      "CSV: ../Project-HDB-Store/staging/stat_monthly.csv imported successfully. Number of records :    288, stat_monthly:year_month\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing column provided to 'parse_dates': 'year'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m datasets \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstat_monthly.csv\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstat_monthly\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear_month\u001b[39m\u001b[38;5;124m'\u001b[39m},\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstat_yearly.csv\u001b[39m\u001b[38;5;124m'\u001b[39m:  {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstat_yearly\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m},\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMain_final.csv\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear_month\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m datafile, info \u001b[38;5;129;01min\u001b[39;00m datasets\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 8\u001b[0m     populate_table(datafile, info)\n",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m, in \u001b[0;36mpopulate_table\u001b[0;34m(data_file, info)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data_file:\n\u001b[1;32m      7\u001b[0m     data_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Project-HDB-Store/staging/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_file,\n\u001b[1;32m     10\u001b[0m                  low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m                  parse_dates\u001b[38;5;241m=\u001b[39m[index_name],   \u001b[38;5;66;03m# convert to datetime during read\u001b[39;00m\n\u001b[1;32m     12\u001b[0m                  index_col\u001b[38;5;241m=\u001b[39mindex_name)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Create engine\u001b[39;00m\n\u001b[1;32m     15\u001b[0m engine \u001b[38;5;241m=\u001b[39m create_engine(psql\u001b[38;5;241m.\u001b[39mconnection_url)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1723\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:161\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_usecols_names(\n\u001b[1;32m    156\u001b[0m             usecols,\n\u001b[1;32m    157\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    158\u001b[0m         )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_parse_dates_presence(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames)  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_noconvert_columns()\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/base_parser.py:242\u001b[0m, in \u001b[0;36mParserBase._validate_parse_dates_presence\u001b[0;34m(self, columns)\u001b[0m\n\u001b[1;32m    232\u001b[0m missing_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m    234\u001b[0m         {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m     )\n\u001b[1;32m    240\u001b[0m )\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing column provided to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_dates\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m     )\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# Convert positions to actual column names\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    247\u001b[0m     col \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns) \u001b[38;5;28;01melse\u001b[39;00m columns[col]\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols_needed\n\u001b[1;32m    249\u001b[0m ]\n",
      "\u001b[0;31mValueError\u001b[0m: Missing column provided to 'parse_dates': 'year'"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    'stat_monthly.csv': {'table_name': 'stat_monthly', 'index_name': 'year_month'},\n",
    "    'stat_yearly.csv':  {'table_name': 'stat_yearly', 'index_name': 'year'},\n",
    "    'Main_final.csv': {'table_name': 'main', 'index_name': 'year_month'}\n",
    "}\n",
    "\n",
    "for datafile, info in datasets.items():\n",
    "    populate_table(datafile, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9581c0-4161-453a-90c9-9ff500c2b2a7",
   "metadata": {},
   "source": [
    "### ‚ñ∂Ô∏è Execute File Processor 2: **Populate Tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019707bf-89f2-4c8b-9e0f-12b7191efc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'Births.csv': {'table_name': 'births', 'index_name': 'year_month'},\n",
    "    'gdp.csv': {'table_name': 'gdp', 'index_name': 'year'},\n",
    "    'Marriages.csv': {'table_name': 'marriages', 'index_name': 'year'},\n",
    "    'Divorces.csv': {'table_name': 'divorces', 'index_name': 'year'},\n",
    "    'Inflation.csv': {'table_name': 'inflation', 'index_name': 'year'},\n",
    "    'unemployment.csv': {'table_name': 'unemployment', 'index_name': 'year'},\n",
    "}\n",
    "\n",
    "for datafile, info in files.items():\n",
    "    filename= f'../Project-HDB-Store/working/{datafile}'\n",
    "    print(filename, info)\n",
    "    populate_table(filename, info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
